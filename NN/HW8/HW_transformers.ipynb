{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:05.125787Z",
     "start_time": "2024-11-21T10:25:05.119443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/character-tokenizer\")\n",
    "from charactertokenizer import CharacterTokenizer\n",
    "\n",
    "chars = \"–ê–∞–ë–±–í–≤–ì–≥–î–¥–ï–µ–Å—ë–ñ–∂–ó–∑–ò–∏–ô–π–ö–∫–õ–ª–ú–º–ù–Ω–û–æ–ü–ø–†—Ä–°—Å–¢—Ç–£—É–§—Ñ–•—Ö–¶—Ü–ß—á–®—à–©—â–™—ä–´—ã–¨—å–≠—ç–Æ—é–Ø—è\"\n",
    "model_max_length = 64\n",
    "tokenizer = CharacterTokenizer(chars, model_max_length)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "example = \"–ü—Ä–∏–≤–µ—Ç\"\n",
    "tokens = tokenizer(example)\n",
    "print(tokens)"
   ],
   "metadata": {
    "id": "I5FSPMOSncpI",
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:05.435296Z",
     "start_time": "2024-11-21T10:25:05.431470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "–ó–∞–¥–∞–Ω–∏–µ: –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±—É–∫–≤ –¥–ª—è –∑–∞–¥–∞—á–∏ —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∏ —É–¥–∞—Ä–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–æ–≤ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ transformers. –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –æ—Ç—Å—é–¥–∞: https://github.com/Koziev/NLP_Datasets/blob/master/Stress/all_accents.zip\n",
    "\n",
    "1. –ù–∞–ø–∏—à–∏—Ç–µ –∫–ª–∞—Å—Å –¥–ª—è Dataset/Dataloder –∏ —Ä–∞–∑–±–µ–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–µ train / test —Å–ø–ª–∏—Ç—ã –≤ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏ 50:50. (1 –±–∞–ª–ª)\n",
    "2. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–±—É—á–∏—Ç—å –æ–¥–Ω—É –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑ –º–æ–¥–µ–ª–µ–π: Bert, Albert, Deberta. –ü–æ—Å—á–∏—Ç–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫—É Accuracy –Ω–∞ train –∏ test. (1 –±–∞–ª–ª). –ü—Ä–∏ –ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–∞ –≤ Accuracy –Ω–∞ test 0.8: (+1 –±–∞–ª–ª), 0.85: (+2 –±–∞–ª–ª–∞), 0.89: (+3 –±–∞–ª–ª–∞).\n",
    "–ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è deberta: https://huggingface.co/IlyaGusev/ru-word-stress-transformer/blob/main/config.json"
   ],
   "metadata": {
    "id": "KQkp36rEoScR"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## –ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–µ–≥–æ"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:08.595863Z",
     "start_time": "2024-11-21T10:25:06.701803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('all_accents.tsv', sep='\\t', header=None, names=['word', 'stressed_word'])"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:11.163106Z",
     "start_time": "2024-11-21T10:25:11.158136Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      word stressed_word\n",
       "0      -–¥–µ          -–¥^–µ\n",
       "1      -–∫–∞          -–∫^–∞\n",
       "2    -–ª–∏–±–æ        -–ª^–∏–±–æ\n",
       "3  -–Ω–∏–±—É–¥—å      -–Ω–∏–±^—É–¥—å\n",
       "4       -—Å            -—Å"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>stressed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-–¥–µ</td>\n",
       "      <td>-–¥^–µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-–∫–∞</td>\n",
       "      <td>-–∫^–∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-–ª–∏–±–æ</td>\n",
       "      <td>-–ª^–∏–±–æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-–Ω–∏–±—É–¥—å</td>\n",
       "      <td>-–Ω–∏–±^—É–¥—å</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-—Å</td>\n",
       "      <td>-—Å</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### –°–¥–µ–ª–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:12.382381Z",
     "start_time": "2024-11-21T10:25:12.379156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_stress_position(word, stressed_word):\n",
    "    index = stressed_word.find('^')\n",
    "    if index == -1:\n",
    "        return None  # –ù–∞ —Å–ª—É—á–∞–π \"–ø—Ä–∏–∫–æ–ª–æ–≤\" –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    "    # –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª '^' –∏–∑ —Å–ª–æ–≤–∞ —Å —É–¥–∞—Ä–µ–Ω–∏–µ–º\n",
    "    stressed_word_clean = stressed_word.replace('^', '')\n",
    "    assert word == stressed_word_clean, f\"Words do not match: {word} != {stressed_word_clean}\"\n",
    "    return index  # –ü–æ–∑–∏—Ü–∏—è —É–¥–∞—Ä–Ω–æ–π –±—É–∫–≤—ã –≤ —Å–ª–æ–≤–µ"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:18.036807Z",
     "start_time": "2024-11-21T10:25:12.771285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['stress_position'] = data.apply(lambda row: get_stress_position(row['word'], row['stressed_word']), axis=1)\n",
    "data = data.dropna(subset=['stress_position'])\n",
    "data['stress_position'] = data['stress_position'].astype(int)\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:18.272903Z",
     "start_time": "2024-11-21T10:25:18.036807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.5, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:18.277598Z",
     "start_time": "2024-11-21T10:25:18.273907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class StressDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.words = data['word'].tolist()\n",
    "        self.stress_positions = data['stress_position'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.words[idx]\n",
    "        stress_pos = self.stress_positions[idx]\n",
    "\n",
    "        encoding = self.tokenizer(word, return_tensors='pt', padding='max_length', truncation=True)\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "\n",
    "        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞\n",
    "        labels = torch.full(input_ids.shape, -100)  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–æ–∑–∏—Ü–∏–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤\n",
    "        # –ü–æ–∑–∏—Ü–∏—è —Å–∏–º–≤–æ–ª–∞ —Å–º–µ—â–µ–Ω–∞ –Ω–∞ 1 –∏–∑-–∑–∞ [CLS] —Ç–æ–∫–µ–Ω–∞\n",
    "        labels[stress_pos + 1] = 1  # –£–¥–∞—Ä–Ω—ã–π —Å–∏–º–≤–æ–ª\n",
    "        # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã\n",
    "        for i in range(1, len(word) + 1):\n",
    "            if labels[i] != 1:\n",
    "                labels[i] = 0  # –ù–µ—É–¥–∞—Ä–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏  \n",
    "–í–∑—è–ª Deberta (\"–∞ —á—Ç–æ, —è –ø–∞–ª—å—Ü–µ–º –¥–µ–ª–∞–Ω–Ω—ã–π —á—Ç–æ-–ª–∏ - –∫–æ–Ω–µ—á–Ω–æ –æ—Å–∏–ª—é –Ω–∞ —Å–≤–æ—ë–º –∂–µ–ª–µ–∑–µ —Å–∞–º—É—é —Ç—è–∂—ë–ª—É—é –º–æ–¥–µ–ª—å...\")\n",
    "\n",
    "PS. –û—Å–∏–ª–∏–ª, –Ω–æ –Ω–µ –¥–æ –∫–æ–Ω—Ü–∞"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:18.284156Z",
     "start_time": "2024-11-21T10:25:18.277598Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import DebertaForTokenClassification, Trainer, TrainingArguments",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤–æ–∑—å–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –≤ —É—Å–ª–æ–≤–∏–∏ –∑–∞–¥–∞—á–∏"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:20.373377Z",
     "start_time": "2024-11-21T10:25:19.466347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = CharacterTokenizer(chars, model_max_length)\n",
    "\n",
    "# –í–æ–∑—å–º—ë–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "model = DebertaForTokenClassification.from_pretrained('microsoft/deberta-base', num_labels=2)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:21.225189Z",
     "start_time": "2024-11-21T10:25:21.185440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = StressDataset(train_data, tokenizer)\n",
    "test_dataset = StressDataset(test_data, tokenizer)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ accuracy"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:22.432417Z",
     "start_time": "2024-11-21T10:25:22.429133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "\n",
    "    pred_flat = preds.flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    mask = labels_flat != -100\n",
    "    pred_flat = pred_flat[mask]\n",
    "    labels_flat = labels_flat[mask]\n",
    "\n",
    "    return {'accuracy': accuracy_score(labels_flat, pred_flat)}"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Transformers"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:23.848329Z",
     "start_time": "2024-11-21T10:25:23.782984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_dir='./logs',\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zacgr\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:25:26.152612Z",
     "start_time": "2024-11-21T10:25:25.906002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[40], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_metrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\transformers\\utils\\deprecation.py:165\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action\u001B[38;5;241m.\u001B[39mNOTIFY, Action\u001B[38;5;241m.\u001B[39mNOTIFY_ALWAYS):\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m--> 165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\transformers\\trainer.py:424\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001B[0m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_func \u001B[38;5;241m=\u001B[39m compute_loss_func\n\u001B[0;32m    423\u001B[0m \u001B[38;5;66;03m# Seed must be set before instantiating the model when using model\u001B[39;00m\n\u001B[1;32m--> 424\u001B[0m enable_full_determinism(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mseed) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mfull_determinism \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mset_seed\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    426\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhp_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdeepspeed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\transformers\\trainer_utils.py:105\u001B[0m, in \u001B[0;36mset_seed\u001B[1;34m(seed, deterministic)\u001B[0m\n\u001B[0;32m    103\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(seed)\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n\u001B[1;32m--> 105\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmanual_seed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mmanual_seed_all(seed)\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\torch\\_compile.py:31\u001B[0m, in \u001B[0;36m_disable_dynamo.<locals>.inner\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     28\u001B[0m     disable_fn \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mdisable(fn, recursive)\n\u001B[0;32m     29\u001B[0m     fn\u001B[38;5;241m.\u001B[39m__dynamo_disable \u001B[38;5;241m=\u001B[39m disable_fn\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdisable_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:600\u001B[0m, in \u001B[0;36mDisableContext.__call__.<locals>._fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    598\u001B[0m prior \u001B[38;5;241m=\u001B[39m set_eval_frame(callback)\n\u001B[0;32m    599\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 600\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    601\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    602\u001B[0m     set_eval_frame(prior)\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\torch\\random.py:46\u001B[0m, in \u001B[0;36mmanual_seed\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcuda\u001B[39;00m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_is_in_bad_fork():\n\u001B[1;32m---> 46\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmanual_seed_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmps\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mmps\u001B[38;5;241m.\u001B[39m_is_in_bad_fork():\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\torch\\cuda\\random.py:127\u001B[0m, in \u001B[0;36mmanual_seed_all\u001B[1;34m(seed)\u001B[0m\n\u001B[0;32m    124\u001B[0m         default_generator \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdefault_generators[i]\n\u001B[0;32m    125\u001B[0m         default_generator\u001B[38;5;241m.\u001B[39mmanual_seed(seed)\n\u001B[1;32m--> 127\u001B[0m \u001B[43m_lazy_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed_all\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\torch\\cuda\\__init__.py:244\u001B[0m, in \u001B[0;36m_lazy_call\u001B[1;34m(callable, **kwargs)\u001B[0m\n\u001B[0;32m    242\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_lazy_call\u001B[39m(\u001B[38;5;28mcallable\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_initialized():\n\u001B[1;32m--> 244\u001B[0m         \u001B[38;5;28;43mcallable\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    246\u001B[0m         \u001B[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001B[39;00m\n\u001B[0;32m    247\u001B[0m         \u001B[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001B[39;00m\n\u001B[0;32m    248\u001B[0m         \u001B[38;5;66;03m# else here if this ends up being important.\u001B[39;00m\n\u001B[0;32m    249\u001B[0m         \u001B[38;5;28;01mglobal\u001B[39;00m _lazy_seed_tracker\n",
      "File \u001B[1;32m~\\Documents\\GitReps\\technopark\\NN\\.venv_nn\\Lib\\site-packages\\torch\\cuda\\random.py:125\u001B[0m, in \u001B[0;36mmanual_seed_all.<locals>.cb\u001B[1;34m()\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(device_count()):\n\u001B[0;32m    124\u001B[0m     default_generator \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdefault_generators[i]\n\u001B[1;32m--> 125\u001B[0m     \u001B[43mdefault_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmanual_seed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "–ó–¥–µ—Å—å –º–Ω–µ —Ä–µ–∑–∫–æ —Å—Ç–∞–ª–æ \"–±–æ–ª—å–Ω–æ\", —Ç–∞–∫ –∫–∞–∫ –º–∞–ª–æ —Ç–æ–≥–æ, —á—Ç–æ –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å –ø–æ—á—Ç–∏ 31 —á–∞—Å, —Ç–∞–∫ –µ—â—ë –∏ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –æ–±—É—á–µ–Ω–∏–µ —Å –æ—à–∏–±–∫–æ–π –∏–∑-–∑–∞ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –ø–∞–º—è—Ç–∏. –Ø —Å–≤—è–∑—ã–≤–∞—é —ç—Ç–æ —Å —Ç–µ–º, —á—Ç–æ –≤—ã–±—Ä–∞–≤ Deberta —è \"–≤—ã—Å—Ç—Ä–µ–ª–∏–ª —Å–µ–±–µ –≤ –Ω–æ–≥—É\". –í–æ–∑–º–æ–∂–Ω–æ –æ–±—ã—á–Ω–∞—è BERT —Å–ø—Ä–∞–≤–∏–ª–∞—Å—å –±—ã –±—ã—Å—Ç—Ä–µ–µ.  \n",
    "–û–¥–Ω–∞–∫–æ, –∫–∞–∫ –≤–∏–¥–Ω–æ –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è, —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —ç–ø–æ—Ö–∏ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 0.98. –ê —ç—Ç–æ –≤—ã—à–µ, —á–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –ø–æ–ª–Ω—ã–π –±–∞–ª–ª. –¢–∞–∫ –∫–∞–∫ —É—Å–ª–æ–≤–∏—è –∑–∞–¥–∞—á–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã, —Ç–æ —è –Ω–µ —Ä–∏—Å–∫–Ω—É–ª –ø–æ–≤—Ç–æ—Ä—è—Ç—å —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –¥—Ä—É–≥–æ–π –º–æ–¥–µ–ª—å—é, —Ç–∞–∫ –∫–∞–∫ —É –º–µ–Ω—è –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ –±—ã –≤—Ä–µ–º–µ–Ω–∏."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é –ø—Ä–∏ –≤—ã–ª–µ—Ç–µ –≤ –Ω–æ—É—Ç–±—É–∫–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª–æ—Å—å –∑–Ω–∞—á–µ–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è, –æ–¥–Ω–∞–∫–æ –≤—Å–µ –æ–Ω–∏ –µ—Å—Ç—å –≤ /logs tensorboard-–∞.  \n",
    "### –ó–¥–µ—Å—å –ø—Ä–∏–≤–µ–¥—É —Å–∫—Ä–∏–Ω—ã –æ—Ç—Ç—É–¥–∞. –ö–∞–∫ –≤–∏–¥–Ω–æ, —Ç–æ—á–Ω–æ—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 0,9849\n",
    "–î–ª—è eval:   \n",
    "<img src=\"pictures/eval_accuracy.png\" alt=\"Alt text\">  \n",
    "\n",
    "–î–ª—è train:  \n",
    "<img alt=\"Alt text\" src=\"pictures/train_accuracy.png\"/>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
