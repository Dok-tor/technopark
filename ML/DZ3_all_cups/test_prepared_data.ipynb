{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-21T08:25:35.987472Z",
     "start_time": "2024-04-21T08:25:35.553923Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "with open('train_test_data.pickle', 'rb') as file:\n",
    "    train_test_data = pickle.load(file)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:25:36.003473Z",
     "start_time": "2024-04-21T08:25:35.988472Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "76e051a443fc02e3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:25:36.607217Z",
     "start_time": "2024-04-21T08:25:36.004472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "VAL_DATA = pd.read_csv(\"test.csv\")\n",
    "# VAL_DATA = test_df['title'].values"
   ],
   "id": "295341d2982e5f4e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:25:38.493932Z",
     "start_time": "2024-04-21T08:25:36.608219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from my_librery import *"
   ],
   "id": "50ef58231c522936",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:25:38.508931Z",
     "start_time": "2024-04-21T08:25:38.494932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "TOKEN_PATTERN = \"[а-яё]+\"\n",
    "STOP_WORDS = nltk.corpus.stopwords.words('russian') + nltk.corpus.stopwords.words('english')"
   ],
   "id": "cfb8d95a44fff476",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T20:24:57.873566Z",
     "start_time": "2024-04-17T20:24:14.524891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import RobustScaler, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'features',\n",
    "        ColumnTransformer([\n",
    "            (\n",
    "                'url',\n",
    "                TfidfVectorizer(max_df=0.05, min_df=1, ngram_range=(0, 3)),\n",
    "                'url'\n",
    "            ),\n",
    "            (\n",
    "                'title',\n",
    "                TfidfVectorizer(max_df=0.05, min_df=4, ngram_range=(0, 3)),\n",
    "                'title'\n",
    "            )\n",
    "        ])\n",
    "    ),\n",
    "    ('norm', Normalizer()),\n",
    "    ('scale', RobustScaler(with_centering=False)),\n",
    "    ('clf', nb.BernoulliNB())\n",
    "])\n",
    "fit_predict(pipeline, *train_test_data)"
   ],
   "id": "9c59bee23c9ab84c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9648792960818229, 'test': 0.952919596453684}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T10:10:30.443595Z",
     "start_time": "2024-04-18T10:08:47.499450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'features', \n",
    "        ColumnTransformer([\n",
    "            (\n",
    "                'url',\n",
    "                TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3)), \n",
    "                'url'\n",
    "            ),\n",
    "            (\n",
    "                'title',\n",
    "                TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3)),\n",
    "                'title'\n",
    "            )\n",
    "        ])\n",
    "    ),\n",
    "    ('clf', MultinomialNB(alpha=1))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'features__title__max_df': [0.05, 0.04, 0.06, 0.08, 0.1],\n",
    "    'features__title__min_df': [3,  2, 4, 5],\n",
    "    'features__title__ngram_range': [(0, 3), (0, 2), (0, 4), (0, 5)],\n",
    "\n",
    "    # Добавьте другие параметры, которые хотите варьировать\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=parameters, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train_test_data[0], train_test_data[1])\n",
    "\n",
    "# Лучшие параметры и оценщик\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "print(\"Лучший оценщик:\", grid_search.best_estimator_)"
   ],
   "id": "f6e792bf26847271",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Лучшие параметры: {'features__title__max_df': 0.06, 'features__title__min_df': 2, 'features__title__ngram_range': (0, 2)}\n",
      "Лучший оценщик: Pipeline(steps=[('features',\n",
      "                 ColumnTransformer(transformers=[('url',\n",
      "                                                  TfidfVectorizer(max_df=0.05,\n",
      "                                                                  min_df=3,\n",
      "                                                                  ngram_range=(0,\n",
      "                                                                               3)),\n",
      "                                                  'url'),\n",
      "                                                 ('title',\n",
      "                                                  TfidfVectorizer(max_df=0.06,\n",
      "                                                                  min_df=2,\n",
      "                                                                  ngram_range=(0,\n",
      "                                                                               2)),\n",
      "                                                  'title')])),\n",
      "                ('clf', MultinomialNB(alpha=1))])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:25:50.304482Z",
     "start_time": "2024-04-21T08:25:49.745234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def remove_unicode(df, column):\n",
    "    df[column] = df[column].apply(lambda x: ''.join(i for i in x if ord(i)<128))\n",
    "    return df\n",
    "\n",
    "train_df_new = remove_unicode(train_test_data[0], 'title')\n",
    "val_df_new = remove_unicode(train_test_data[2], 'title')"
   ],
   "id": "cc0b3e887ba8189",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:26:43.071930Z",
     "start_time": "2024-04-21T08:26:43.068928Z"
    }
   },
   "cell_type": "code",
   "source": "new_train_test_data = [train_df_new, train_test_data[1], val_df_new, train_test_data[3]]",
   "id": "80dc9dc9dd450f7d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T10:12:10.166279Z",
     "start_time": "2024-04-18T10:10:30.444598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\n",
    "        'features',\n",
    "        ColumnTransformer([\n",
    "            (\n",
    "                'url',\n",
    "                TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3)),\n",
    "                'url'\n",
    "            ),\n",
    "            (\n",
    "                'title',\n",
    "                TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3)),\n",
    "                'title'\n",
    "            )\n",
    "        ])\n",
    "    ),\n",
    "    ('clf', MultinomialNB(alpha=1))\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'features__title__max_df': [0.05, 0.04, 0.06, 0.08, 0.1],\n",
    "    'features__title__min_df': [3,  2, 4, 5],\n",
    "    'features__title__ngram_range': [(0, 3), (0, 2), (0, 4), (0, 5)],\n",
    "\n",
    "    # Добавьте другие параметры, которые хотите варьировать\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid=parameters, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(new_train_test_data[0], new_train_test_data[1])\n",
    "\n",
    "# Лучшие параметры и оценщик\n",
    "print(\"Лучшие параметры:\", grid_search.best_params_)\n",
    "print(\"Лучший оценщик:\", grid_search.best_estimator_)"
   ],
   "id": "f3fb8aeee104aed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "Лучшие параметры: {'features__title__max_df': 0.06, 'features__title__min_df': 2, 'features__title__ngram_range': (0, 2)}\n",
      "Лучший оценщик: Pipeline(steps=[('features',\n",
      "                 ColumnTransformer(transformers=[('url',\n",
      "                                                  TfidfVectorizer(max_df=0.05,\n",
      "                                                                  min_df=3,\n",
      "                                                                  ngram_range=(0,\n",
      "                                                                               3)),\n",
      "                                                  'url'),\n",
      "                                                 ('title',\n",
      "                                                  TfidfVectorizer(max_df=0.06,\n",
      "                                                                  min_df=2,\n",
      "                                                                  ngram_range=(0,\n",
      "                                                                               2)),\n",
      "                                                  'title')])),\n",
      "                ('clf', MultinomialNB(alpha=1))])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:59:50.731850Z",
     "start_time": "2024-04-18T15:59:46.386736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "the_best = Pipeline(steps=[('features',\n",
    "                 ColumnTransformer(transformers=[('url',\n",
    "                                                  TfidfVectorizer(max_df=0.05,\n",
    "                                                                  min_df=3,\n",
    "                                                                  ngram_range=(0,\n",
    "                                                                               3)),\n",
    "                                                  'url'),\n",
    "                                                 ('title',\n",
    "                                                  TfidfVectorizer(max_df=0.06,\n",
    "                                                                  min_df=2,\n",
    "                                                                  ngram_range=(0,\n",
    "                                                                               2)),\n",
    "                                                  'title')])),\n",
    "                ('clf', MultinomialNB(alpha=1))])\n",
    "fit_predict(the_best, *train_test_data)\n"
   ],
   "id": "72cf767fc25a8da1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.9717577525904313, 'test': 0.9635322483423749}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:51:13.156467Z",
     "start_time": "2024-04-18T15:51:13.109955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "the_best = Pipeline(steps=[('features',\n",
    "                 ColumnTransformer(transformers=[('url',\n",
    "                                                  TfidfVectorizer(max_df=0.05,\n",
    "                                                                  min_df=3,\n",
    "                                                                  ngram_range=(0,\n",
    "                                                                               3)),\n",
    "                                                  'url'),\n",
    "                                                 ('title',\n",
    "                                                  TfidfVectorizer(max_df=0.06,\n",
    "                                                                  min_df=2,\n",
    "                                                                  ngram_range=(0,\n",
    "                                                                               2)),\n",
    "                                                  'title')])),\n",
    "                ('clf', MultinomialNB(alpha=1))])\n",
    "# fit_predict(the_best, *new_train_test_data)\n"
   ],
   "id": "4f6718ecb759fdf8",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:27:44.817835Z",
     "start_time": "2024-04-21T08:27:44.794324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "all_data = pd.concat([new_train_test_data[0], new_train_test_data[2]])\n",
    "all_y = np.concatenate([new_train_test_data[1], new_train_test_data[3]])\n",
    "\n",
    "# Предположим, что df - это ваш DataFrame, а labels - это ваш массив numpy с метками классов\n",
    "labels_df = pd.DataFrame(all_y, columns=['label'])\n",
    "all_data.reset_index(drop=True, inplace=True)\n",
    "# Конкатенируем df и labels_df\n",
    "all_data_frame = pd.concat([all_data, labels_df],axis=1)\n",
    "all_data_frame.shape"
   ],
   "id": "ee187e2461fd54f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135309, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T08:28:51.991942Z",
     "start_time": "2024-04-21T08:28:51.927899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_total_length(text):\n",
    "    return len(text.split()) > 3\n",
    "\n",
    "# применяем функцию к колонке 'title' и оставляем только те строки, где общая длина всех слов больше или равна трем\n",
    "df = all_data_frame[all_data_frame['title'].apply(check_total_length)]\n",
    "\n",
    "df.shape"
   ],
   "id": "224accbb0e92dfbf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120027, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:07:28.293961Z",
     "start_time": "2024-04-18T18:07:27.906735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Предположим, что df - это ваш DataFrame, а train_values - это ваши метки классов\n",
    "\n",
    "\n",
    "# Отфильтровываем строки, принадлежащие классу 1\n",
    "class_1_titles = all_data_frame[all_data_frame['label'] == 0]['title']\n",
    "\n",
    "# Разбиваем строки на слова и подсчитываем количество каждого слова\n",
    "word_counts = Counter()\n",
    "for title in class_1_titles:\n",
    "    words = re.findall(r'\\b\\w+\\b', title)\n",
    "    word_counts.update(words)\n",
    "\n",
    "# Выводим наиболее часто встречающиеся слова\n",
    "# print(word_counts.most_common())\n",
    "# Получаем список наиболее часто встречающихся слов\n",
    "most_common_words = word_counts.most_common()\n",
    "\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "# Фильтруем список, чтобы оставить только слова, которые встречаются более 170 раз\n",
    "words_over_170 = [word for word, count in most_common_words if count > 170 and not is_number(word)]\n",
    "\n",
    "# Выводим результат\n",
    "print(words_over_170)"
   ],
   "id": "ab66cd4bb0dcea98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['online', 'free', 'download', 'buy', 'mailru', 'search', 'page', 's', 'watch', 'price', 'results', 'photos', 'moscow', 'read', 'reviews', 'store', 'russian', 'photo', 'prices', 'russia', 'region', 'mp3', 'sale', 'st', 'new', 'work', 'world', 'years', 'video', 'old', 'book', 'good', 'thousand', 'listen', 'quality', 'company', 'rubles', 'district', 'without', 'children', 'series', 'petersburg', 'music', 'parts', 'tv', 'news', 'car', 'grade', 'women', 'weather', 'house', 'dating', 'website', 'olx', 'torrent', 'apartment', 'forum', 'school', 'black', 'phone', 'season', 'best', 'equipment', 'vacancy', 'service', 'hd', 'rent', 'delivery', 'number', 'city', 'episode', 'registration', 'game', 'books', 'million', 'user', 'song', 'ukraine', 'auto', 'order', 'uah', 'used', 'chapter', 'rub', 'cars', 'state', 'street', 'catalog', 'services', 'topic', 'center', 'spare', 'vacancies', 'products', 'site', 'address', 'm', 'information', 'minsk', 'llc', 'dream', 'love', 'one', 'home', 'games', 'mail', 'manga', 'men', 'life', 'toyota', 'movie', 'film', 'official', 'white', 'group', 'kyiv', 'selling', 'day', 'album', 'part', 'history', 'job', 'movies', 'gdz', 'hotel', 'full', 'forecast', 'library', 'club', 'system', 'review', 'description', 'language', 'people', 'category', 'september', 'article', 'time', 'portal', 'krasnodar', 'girl', 'girls', 'business', 'base', 'find', 'today', 'word', 'art', 'songs', 'cian', 'post', 'community', 'sports', 'station', 'map', 'personal', 'first', 'films', 'videos', 'village', 'program', 'date', 'profile', 'like', 'id', 'instructions', 'list', 'wholesale', 'office', 'ad', 'recipe', 'meet', 'social', 'republic', 'goods', 'schedule', 'furniture', 'network', 'get', 'english', 'metro', 'set', 'man', 'guy', 'via', 'repair', 'l', 'days', 'market', 'low', 'mir', 'collection', 'lyrics', 'answers', 'winter', 'characteristics', 'alexander', 'two', 'automatic', 'test', 'play', 'blue', 'make', 'vladivostok', 'samara', 'red', 'novgorod', 'educational', 'pictures', 'advertisement', 'construction', 'football', 'belarus', 'child', 'year', 'android', 'nt', 'made', 'federation', 'shoes', 'moi', 'use', 'image', 'fb2', 'wedding', 'nizhny', 'promua', 'everything', 'help', 'krasnoyarsk', 'found', 'health', 'water', 'design', 'case', 'electronic', 'chelyabinsk', 'general', 'wheels', 'almaty', 'exchange', 'contacts', 'kazakhstan', 'trucks', 'telephone', 'numbers', 'accessories', 'air', 'development', 'mobile', 'sell', 'power', 'room', 'live', 'transmission', 'view', 'teachers', 'windows', 'clothing', 'real', 'recipes', 'boots', 'train', 'complex', 'compare', 'advertisements', 'dated', 'color', 'family', 'rating', 'novosibirsk', 'lesson', 'card', 'land', 'road', 'internet', 'treatment', 'medical', 'mitsubishi', 'scientific', 'liters', 'electric', 'body', 'anime', 'ads', 'beauty', 'oil', 'drive2', 'education', 'ekaterinburg', 'purchase', 'omsk', 'money', 'joint', 'vladimir', 'section', 'discussion', 'pc', 'addresses', 'beautiful', 'bank', 'technical', 'selection', 'driver', 'n', 'yekaterinburg', 'food', 'engine', 'heart', 'types', 'code', 'woman', 'babyblogru', 'nissan', 'dress', 'radio', 'kharkov', 'large', 'tires', 'c', 'mathematics', 'samsung', 'looking', 'training', 'legal', 'v', 'long', 'law', 'hair', 'translation', 'floor', 'hosting', 'main', 'analysis', 'version', 'country', 'aged', 'high', 'mm', 'original', 'voronezh', 'control', 'episodes', 'cm', 'size', 'interpretation', 'manager', 'apartments', 'tours', 'author', 'perm', 'file', 'top', 'hours', 'special', 'tickets', 'customer', 'united', 'drive', 'text', 'using', 'tin', 'baby', 'head', 'picture', 'details', 'ministry', 'wallpaper', 'stores', 'g', 'gismeteo', 'latest', 'computer', 'clothes', 'sales', 'manual', 'master', 'week', 'magazine', 'kindergarten', 'irkutsk', 'posting', 'light', 'specifications', 'presentation', 'retail', 'pdf', 'x', 'project', 'ip', 'elena', 'resume', 'take', 'product', 'transport', 'gold', 'department', 'war', 'jacket', 'discounts', 'liveinternet', 'articles', 'right', 'tour', 'marketplace', 'much', 'ogrn', 'payment', 'production', 'kitchen', 'area', 'class', 'machine', 'federal', 'private', 'diary', 'us', 'need', 'gas', 'territory', 'travel', 'purchases', 'tomorrow', 'summer', 'care', 'stations', 'science', 'honda', 'building', 'mods', 'words', 'gta', 'si', 'hands', 'sergey', 'gray', 'companies', 'b', 'metal', 'clip', 'houses', 'board', 'go', 'would', 'gasoline', 'glass', 'channel', 'tyumen', 'account', 'anna', 'night', 'olga', 'great', 'biography', 'open', 'contract', 'model', 'front', 'kazan', 'little', 'story', 'tenge', 'mileage', 'autumn', 'residential', 'application', 'installation', 'mamba', 'de', 'table', 'volkswagen', 'hyundai', 'epub', 'mvideo', 'sport', 'cinema', 'consumer', 'dolls', 'star', 'ukrainian', 'travelers', 'stories', 'fire', 'october', 'asos', 'fellow', 'foreign', 'ufa', 'bmw', 'three', 'detailed', 'lada', 'stepbystep', 'face', 'tashkent', 'silver', 'inexpensively', 'possible', 'military', 'archive', 'studio', 'popular', 'composition', 'blog', 'management', 'upload', 'cat', 'mother', 'desktop', 'yoox', 'small', 'systems', 'zoonru', 'rostovondon', 'km', 'sneakers', 'teacher', 'green', 'plastic', 'mercedesbenz', 'opening', 'show', 'modern', 'sex', 'ratings', 'last', 'garden', 'moment', 'directory', 'let', 'estate', 'questions', 'bus', 'leather', 'irina', 'place', 'barnaul', 'dark', 'materials', 'pro', 'wallpapers', 'khabarovsk', 'kia', 'san', 'cream', 'tests', 'check', 'plant', 'shop', 'r', 'central', 'smart', 'plot', 'apple', 'left', 'protection', 'volgograd', 'research', 'happy', 'gift', 'fastpic', 'agency', 'style', 'models', 'rules', 'around', 'want', 'p', 'andrey', 'sea', 'labor', 'age', 'pregnancy', 'programs', 'minecraft', 'step', 'renault', 'natural', 'rental', 'comments', 'microdistrict', 'magic', 'give', 'gallery', 'tatyana', 'problems', 'condition', 'form', 'name', 'rear', 'odessa', 'field', 'armtek', 'international', 'alexey', 'death', 'birthday', 'ml', 'call', 'competitive', 'longterm', 'knitting', 'wheel', 'crimea', 'paper', 'plus', '3d', 'bag', 'truck', 'hotels', 'person', 'mark', 'interior', 'simulator', 'professional', 'taborru', 'methods', 'dictionary', 'features', 'trailers', 'player', 'super', 'pcs', 'coat', 'kemerovo', 'oneroom', 'according', 'standard', 'back', 'public', 'query', 'ford', 'motor', 'jobs', 'fuel', 'penza', 'economic', 'fishing', 'activities', 'meeting', 'blablacarru', 'owner', 'safety', 'chair', 'security', 'national', 'second', 'see', 'throughout', 'sun', 'side', 'may', '1st', 'interesting', 'problem', 'mod', 'credit', 'per', 'tax', 'friends', 'funny', 'august', 'working', 'report', 'works', 'named', 'cost', 'near', 'start', 'big', 'sedan', 'park', 'toys', 'iphone', 'newrutororg', 'communication', 'shopping', 'space', 'mini', 'insurance', 'literature', 'images', 'andreas', 'german', 'saratov', 'secret', 'mirror', 'door', 'manufacturer', 'police', 'rooms', 'bed', 'hassle', 'choose', 'steel', 'stock', 'culture', 'wall', 'individual', 'look', 'secondary', 'workbook', 'doors', 'sochi', 'guide', 'hand', 'clinic', 'organization', 'feat', 'know', 'exercise', 'housing', 'advice', 'loveplanetru', 'flowers', 'documents', 'doctor', 'drama', 'tips', 'actors', 'plan', 'synonyms', 'month', 'ii', 'suit', 'e', 'subtitles', 'young', 'icon', 'mercedes', 'cosmetics', 'line', 'dmitry', 'simple', 'yaroslavl', 'database', 'algebra', 'poems', 'hot', 'procedure', 'blood', 'action', 'support', 'ideas', 'operator', 'team', 'hp', 'match', 'dog', 'choice', 'albums', 'institution', 'washing', 'december', 'jewelry', 'cover', 'thank', 'wife', 'many', 'pages', 'owners', 'university', 'chicken', 'fish', 'kirov', 'golden', 'society', 'rutube', 'weight', 'salon', 'txt', 'technology', 'trade', 'king', 'solution', 'short', 'chevrolet', 'marina', 'videomailru', 'svetlana', 'dogs', 'germany', 'voice', 'route', 'task', 'course', 'vaz', 'unified', 'box', 'fairy']\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:23:28.871256Z",
     "start_time": "2024-04-18T18:23:28.853803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Функция для создания нового признака\n",
    "def words_presence_feature(df, words):\n",
    "    return df.apply(lambda x: 1 if any(word in x for word in words) else 0).to_frame()\n",
    "\n",
    "# Создаем список слов, которые вы хотите проверить\n",
    "words_to_check = ['porn', 'sex', 'fuck', 'dick', 'pussy', 'sperm', 'webcam', 'boobs',]\n",
    "\n",
    "# words_to_check = ['porn', 'sex', 'xxx', 'girls', 'big', 'anal', 'naked', 'pussy', 'ass', 'biqle', 'tits', 'fucked', 'daftsex', 'blowjob', 'sexy', 'erotic', 'nude', 'dick', 'porno', 'fuck', 'fucks', 'fucking', 'erotica', 'milf', 'ancensored', 'cum', 'amateur', 'hardcore', 'adult', 'busty', 'lesbian', 'cock', 'homemade', 'xvideos', 'stockings', 'gay', 'chick', 'lesbians', 'boobs', 'masturbation', 'group']\n",
    "for_1_class = FunctionTransformer(words_presence_feature, validate=False, kw_args={'words': words_to_check})\n",
    "for_0_class = FunctionTransformer(words_presence_feature, validate=False, kw_args={'words': words_over_170})\n"
   ],
   "id": "f3d2f2bf502d803c",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:11:29.959955Z",
     "start_time": "2024-04-18T18:11:29.919910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Добавляем новый признак в пайплайн\n",
    "the_best_1 = Pipeline(steps=[\n",
    "    ('features', ColumnTransformer(transformers=[\n",
    "        ('url', TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3)), 'url'),\n",
    "        ('title', TfidfVectorizer(max_df=0.06, min_df=2, ngram_range=(0, 2)), 'title'),\n",
    "        ('for_1_class', for_1_class, 'title'),\n",
    "        ('for_0_class', for_0_class, 'title')\n",
    "    ])),\n",
    "    ('clf', MultinomialNB(alpha=1))\n",
    "])\n",
    "# fit_predict(the_best_1, *new_train_test_data)"
   ],
   "id": "a1cdc80b0147fc79",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:36:12.610352Z",
     "start_time": "2024-04-18T18:36:12.602351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Word2VecVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=100, window=5, min_count=1, workers=4):\n",
    "        self.vector_size = vector_size\n",
    "        self.window = window\n",
    "        self.min_count = min_count\n",
    "        self.workers = workers\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        sentences = [doc.split() for doc in X]\n",
    "        self.model = Word2Vec(sentences, vector_size=self.vector_size, window=self.window, min_count=self.min_count, workers=self.workers)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([abs(np.mean([self.model.wv[w] for w in doc.split() if w in self.model.wv]\n",
    "                                 or [np.zeros(self.vector_size)], axis=0))\n",
    "                         for doc in X])\n",
    "\n"
   ],
   "id": "5566fdfe71824e83",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T18:37:33.036484Z",
     "start_time": "2024-04-18T18:37:28.009728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "the_best_1 = Pipeline(steps=[\n",
    "    ('features', ColumnTransformer(transformers=[\n",
    "        ('url', TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3)), 'url'),\n",
    "        ('title', TfidfVectorizer(max_df=0.06, min_df=2, ngram_range=(0, 2)), 'title'),\n",
    "        ('for_1_class', for_1_class, 'title'),\n",
    "        ('for_0_class', for_0_class, 'title')\n",
    "    ])),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "fit_predict(the_best_1, *new_train_test_data)"
   ],
   "id": "6ab33aab211ea157",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0.972337019248669, 'test': 0.9671516424178791}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:15:09.679559Z",
     "start_time": "2024-04-18T19:15:09.645016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "def get_ngrams(text, n):\n",
    "    n_grams = nltk.ngrams(text, n)\n",
    "    return [''.join(grams) for grams in n_grams]\n",
    "# sentence = 'лекция протексты'\n",
    "# get_ngrams(sentence, 2)\n",
    "\n",
    "\n",
    "\n",
    "# Создаем функцию для предобработки текста\n",
    "def preprocess_text(text):\n",
    "    # Токенизация\n",
    "    words = word_tokenize(text)\n",
    "    # words = get_ngrams(text, 7)\n",
    "\n",
    "    # Удаление стоп-слов\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Лемматизация\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "# Используем функцию в TfidfVectorizer\n",
    "the_best_1 = Pipeline(steps=[\n",
    "    ('features', ColumnTransformer(transformers=[\n",
    "        ('url', TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3), tokenizer=preprocess_text), 'url'),\n",
    "        ('title', TfidfVectorizer(max_df=0.06, min_df=2, ngram_range=(0, 2), tokenizer=preprocess_text), 'title'),\n",
    "        ('for_1_class', for_1_class, 'title'),\n",
    "        ('for_0_class', for_0_class, 'title')\n",
    "    ])),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "# fit_predict(the_best_1, *new_train_test_data)\n"
   ],
   "id": "b0395edd4b25b7ee",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:16:05.077364Z",
     "start_time": "2024-04-18T19:15:12.131080Z"
    }
   },
   "cell_type": "code",
   "source": "the_best_1.fit(all_data, all_y)",
   "id": "4f1571ae25674808",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ml\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 ColumnTransformer(transformers=[('url',\n",
       "                                                  TfidfVectorizer(max_df=0.05,\n",
       "                                                                  min_df=3,\n",
       "                                                                  ngram_range=(0,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=<function preprocess_text at 0x0000020C175F6EE0>),\n",
       "                                                  'url'),\n",
       "                                                 ('title',\n",
       "                                                  TfidfVectorizer(max_df=0.06,\n",
       "                                                                  min_df=2,\n",
       "                                                                  ngram_range=(0,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=<function preprocess_text at 0x0000020C175F6EE0>),\n",
       "                                                  'title'),\n",
       "                                                 ('for_1_class',\n",
       "                                                  FunctionTransformer...\n",
       "                                                  FunctionTransformer(func=<function words_presence_feature at 0x0000020C05967D30>,\n",
       "                                                                      kw_args={'words': ['online',\n",
       "                                                                                         'free',\n",
       "                                                                                         'download',\n",
       "                                                                                         'buy',\n",
       "                                                                                         'mailru',\n",
       "                                                                                         'search',\n",
       "                                                                                         'page',\n",
       "                                                                                         's',\n",
       "                                                                                         'watch',\n",
       "                                                                                         'price',\n",
       "                                                                                         'results',\n",
       "                                                                                         'photos',\n",
       "                                                                                         'moscow',\n",
       "                                                                                         'read',\n",
       "                                                                                         'reviews',\n",
       "                                                                                         'store',\n",
       "                                                                                         'russian',\n",
       "                                                                                         'photo',\n",
       "                                                                                         'prices',\n",
       "                                                                                         'russia',\n",
       "                                                                                         'region',\n",
       "                                                                                         'mp3',\n",
       "                                                                                         'sale',\n",
       "                                                                                         'st',\n",
       "                                                                                         'new',\n",
       "                                                                                         'work',\n",
       "                                                                                         'world',\n",
       "                                                                                         'years',\n",
       "                                                                                         'video',\n",
       "                                                                                         'old', ...]}),\n",
       "                                                  'title')])),\n",
       "                ('clf', MultinomialNB())])"
      ],
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;url&#x27;,\n",
       "                                                  TfidfVectorizer(max_df=0.05,\n",
       "                                                                  min_df=3,\n",
       "                                                                  ngram_range=(0,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;),\n",
       "                                                  &#x27;url&#x27;),\n",
       "                                                 (&#x27;title&#x27;,\n",
       "                                                  TfidfVectorizer(max_df=0.06,\n",
       "                                                                  min_df=2,\n",
       "                                                                  ngram_range=(0,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;),\n",
       "                                                  &#x27;title&#x27;),\n",
       "                                                 (&#x27;for_1_class&#x27;,\n",
       "                                                  FunctionTransformer...\n",
       "                                                  FunctionTransformer(func=&lt;function words_presence_feature at 0x0000020C05967D30&gt;,\n",
       "                                                                      kw_args={&#x27;words&#x27;: [&#x27;online&#x27;,\n",
       "                                                                                         &#x27;free&#x27;,\n",
       "                                                                                         &#x27;download&#x27;,\n",
       "                                                                                         &#x27;buy&#x27;,\n",
       "                                                                                         &#x27;mailru&#x27;,\n",
       "                                                                                         &#x27;search&#x27;,\n",
       "                                                                                         &#x27;page&#x27;,\n",
       "                                                                                         &#x27;s&#x27;,\n",
       "                                                                                         &#x27;watch&#x27;,\n",
       "                                                                                         &#x27;price&#x27;,\n",
       "                                                                                         &#x27;results&#x27;,\n",
       "                                                                                         &#x27;photos&#x27;,\n",
       "                                                                                         &#x27;moscow&#x27;,\n",
       "                                                                                         &#x27;read&#x27;,\n",
       "                                                                                         &#x27;reviews&#x27;,\n",
       "                                                                                         &#x27;store&#x27;,\n",
       "                                                                                         &#x27;russian&#x27;,\n",
       "                                                                                         &#x27;photo&#x27;,\n",
       "                                                                                         &#x27;prices&#x27;,\n",
       "                                                                                         &#x27;russia&#x27;,\n",
       "                                                                                         &#x27;region&#x27;,\n",
       "                                                                                         &#x27;mp3&#x27;,\n",
       "                                                                                         &#x27;sale&#x27;,\n",
       "                                                                                         &#x27;st&#x27;,\n",
       "                                                                                         &#x27;new&#x27;,\n",
       "                                                                                         &#x27;work&#x27;,\n",
       "                                                                                         &#x27;world&#x27;,\n",
       "                                                                                         &#x27;years&#x27;,\n",
       "                                                                                         &#x27;video&#x27;,\n",
       "                                                                                         &#x27;old&#x27;, ...]}),\n",
       "                                                  &#x27;title&#x27;)])),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;url&#x27;,\n",
       "                                                  TfidfVectorizer(max_df=0.05,\n",
       "                                                                  min_df=3,\n",
       "                                                                  ngram_range=(0,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;),\n",
       "                                                  &#x27;url&#x27;),\n",
       "                                                 (&#x27;title&#x27;,\n",
       "                                                  TfidfVectorizer(max_df=0.06,\n",
       "                                                                  min_df=2,\n",
       "                                                                  ngram_range=(0,\n",
       "                                                                               2),\n",
       "                                                                  tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;),\n",
       "                                                  &#x27;title&#x27;),\n",
       "                                                 (&#x27;for_1_class&#x27;,\n",
       "                                                  FunctionTransformer...\n",
       "                                                  FunctionTransformer(func=&lt;function words_presence_feature at 0x0000020C05967D30&gt;,\n",
       "                                                                      kw_args={&#x27;words&#x27;: [&#x27;online&#x27;,\n",
       "                                                                                         &#x27;free&#x27;,\n",
       "                                                                                         &#x27;download&#x27;,\n",
       "                                                                                         &#x27;buy&#x27;,\n",
       "                                                                                         &#x27;mailru&#x27;,\n",
       "                                                                                         &#x27;search&#x27;,\n",
       "                                                                                         &#x27;page&#x27;,\n",
       "                                                                                         &#x27;s&#x27;,\n",
       "                                                                                         &#x27;watch&#x27;,\n",
       "                                                                                         &#x27;price&#x27;,\n",
       "                                                                                         &#x27;results&#x27;,\n",
       "                                                                                         &#x27;photos&#x27;,\n",
       "                                                                                         &#x27;moscow&#x27;,\n",
       "                                                                                         &#x27;read&#x27;,\n",
       "                                                                                         &#x27;reviews&#x27;,\n",
       "                                                                                         &#x27;store&#x27;,\n",
       "                                                                                         &#x27;russian&#x27;,\n",
       "                                                                                         &#x27;photo&#x27;,\n",
       "                                                                                         &#x27;prices&#x27;,\n",
       "                                                                                         &#x27;russia&#x27;,\n",
       "                                                                                         &#x27;region&#x27;,\n",
       "                                                                                         &#x27;mp3&#x27;,\n",
       "                                                                                         &#x27;sale&#x27;,\n",
       "                                                                                         &#x27;st&#x27;,\n",
       "                                                                                         &#x27;new&#x27;,\n",
       "                                                                                         &#x27;work&#x27;,\n",
       "                                                                                         &#x27;world&#x27;,\n",
       "                                                                                         &#x27;years&#x27;,\n",
       "                                                                                         &#x27;video&#x27;,\n",
       "                                                                                         &#x27;old&#x27;, ...]}),\n",
       "                                                  &#x27;title&#x27;)])),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;url&#x27;,\n",
       "                                 TfidfVectorizer(max_df=0.05, min_df=3,\n",
       "                                                 ngram_range=(0, 3),\n",
       "                                                 tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;),\n",
       "                                 &#x27;url&#x27;),\n",
       "                                (&#x27;title&#x27;,\n",
       "                                 TfidfVectorizer(max_df=0.06, min_df=2,\n",
       "                                                 ngram_range=(0, 2),\n",
       "                                                 tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;),\n",
       "                                 &#x27;title&#x27;),\n",
       "                                (&#x27;for_1_class&#x27;,\n",
       "                                 FunctionTransformer(func=&lt;function words_presenc...\n",
       "                                 FunctionTransformer(func=&lt;function words_presence_feature at 0x0000020C05967D30&gt;,\n",
       "                                                     kw_args={&#x27;words&#x27;: [&#x27;online&#x27;,\n",
       "                                                                        &#x27;free&#x27;,\n",
       "                                                                        &#x27;download&#x27;,\n",
       "                                                                        &#x27;buy&#x27;,\n",
       "                                                                        &#x27;mailru&#x27;,\n",
       "                                                                        &#x27;search&#x27;,\n",
       "                                                                        &#x27;page&#x27;,\n",
       "                                                                        &#x27;s&#x27;,\n",
       "                                                                        &#x27;watch&#x27;,\n",
       "                                                                        &#x27;price&#x27;,\n",
       "                                                                        &#x27;results&#x27;,\n",
       "                                                                        &#x27;photos&#x27;,\n",
       "                                                                        &#x27;moscow&#x27;,\n",
       "                                                                        &#x27;read&#x27;,\n",
       "                                                                        &#x27;reviews&#x27;,\n",
       "                                                                        &#x27;store&#x27;,\n",
       "                                                                        &#x27;russian&#x27;,\n",
       "                                                                        &#x27;photo&#x27;,\n",
       "                                                                        &#x27;prices&#x27;,\n",
       "                                                                        &#x27;russia&#x27;,\n",
       "                                                                        &#x27;region&#x27;,\n",
       "                                                                        &#x27;mp3&#x27;,\n",
       "                                                                        &#x27;sale&#x27;,\n",
       "                                                                        &#x27;st&#x27;,\n",
       "                                                                        &#x27;new&#x27;,\n",
       "                                                                        &#x27;work&#x27;,\n",
       "                                                                        &#x27;world&#x27;,\n",
       "                                                                        &#x27;years&#x27;,\n",
       "                                                                        &#x27;video&#x27;,\n",
       "                                                                        &#x27;old&#x27;, ...]}),\n",
       "                                 &#x27;title&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">url</label><div class=\"sk-toggleable__content\"><pre>url</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.05, min_df=3, ngram_range=(0, 3),\n",
       "                tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">title</label><div class=\"sk-toggleable__content\"><pre>title</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.06, min_df=2, ngram_range=(0, 2),\n",
       "                tokenizer=&lt;function preprocess_text at 0x0000020C175F6EE0&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">for_1_class</label><div class=\"sk-toggleable__content\"><pre>title</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function words_presence_feature at 0x0000020C05967D30&gt;,\n",
       "                    kw_args={&#x27;words&#x27;: [&#x27;porn&#x27;, &#x27;sex&#x27;, &#x27;fuck&#x27;, &#x27;dick&#x27;, &#x27;pussy&#x27;,\n",
       "                                       &#x27;sperm&#x27;, &#x27;webcam&#x27;, &#x27;boobs&#x27;]})</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">for_0_class</label><div class=\"sk-toggleable__content\"><pre>title</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function words_presence_feature at 0x0000020C05967D30&gt;,\n",
       "                    kw_args={&#x27;words&#x27;: [&#x27;online&#x27;, &#x27;free&#x27;, &#x27;download&#x27;, &#x27;buy&#x27;,\n",
       "                                       &#x27;mailru&#x27;, &#x27;search&#x27;, &#x27;page&#x27;, &#x27;s&#x27;, &#x27;watch&#x27;,\n",
       "                                       &#x27;price&#x27;, &#x27;results&#x27;, &#x27;photos&#x27;, &#x27;moscow&#x27;,\n",
       "                                       &#x27;read&#x27;, &#x27;reviews&#x27;, &#x27;store&#x27;, &#x27;russian&#x27;,\n",
       "                                       &#x27;photo&#x27;, &#x27;prices&#x27;, &#x27;russia&#x27;, &#x27;region&#x27;,\n",
       "                                       &#x27;mp3&#x27;, &#x27;sale&#x27;, &#x27;st&#x27;, &#x27;new&#x27;, &#x27;work&#x27;,\n",
       "                                       &#x27;world&#x27;, &#x27;years&#x27;, &#x27;video&#x27;, &#x27;old&#x27;, ...]})</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T15:49:52.744172Z",
     "start_time": "2024-04-18T15:49:52.727725Z"
    }
   },
   "cell_type": "code",
   "source": "len(all_data)",
   "id": "b3179836f6afc73b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135309"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:16:08.766905Z",
     "start_time": "2024-04-18T19:16:08.688180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "with open('VAL_DATA.pickle', 'rb') as file:\n",
    "    VAL_DATA = pickle.load(file)"
   ],
   "id": "d362b747b8d2cf52",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T19:17:14.254202Z",
     "start_time": "2024-04-18T19:16:09.446722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = the_best_1.predict(VAL_DATA)\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df[\"label\"] = results\n",
    "\n",
    "test_df[[\"ID\", \"label\"]].to_csv(\"Current_best_merged.csv\", index=False)"
   ],
   "id": "fce3ad0d4fdfb4ce",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c825a413319a23dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
